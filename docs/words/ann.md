这一章介绍了`神经网络`涉及到的数学及工程方面的（包括所用到的数学的各个分支，及神
经网络的各个研究方向）的一些基本概念、定义、算法等等。

###基础概念

首先来搞清楚几个基本的概念，这些概念之间的区别让很多人都挺迷惑。
NN（神经网络）、ANN（人工神经网络）、DNN（深度神经网络）、DL（深度学习）、ML
（机器学习）、AI（人工智能）、MLP（多层感知机）、CNN（卷积神经网络）、RNN（循环
神经网络）这些词之间是什么关系？

* AI > ML > DL
这些定义里，AI 是最宽泛的定义，而 ML 是 AI 的一种实现方式，其特点是不明确编码，而
让计算机自行学习参数。DL 则是 ML 的子集，DL 指的是使用 DNN 方式实现的 ML，相对于普
通 ML 的特征需要自己选择（即特征工程），DL 的特征无须手动选择（所谓端到端）。

* DL = NN
DL 和 NN 基本是同一个东西，区别在于强调不同方面，DL 是跟 ML 等概念在一个范围内的，
而 NN 则主要强调是其实现的方式。
* NN = ANN = DNN 一般来说，NN=ANN=DNN，指的都是人工神经网络。
* DNN > MLP/CNN/RNN
MLP、CNN 和 RNN 则算是 DNN 的子类（严格来说应该算其要素特点），主要指代其网络中的
全连接、卷积和循环特点。


### 张量/标量/向量/矩阵
张量指的是 N 轴（axis）的数据。轴的个数也被称为阶（order）。
* 标量（Scalar）：0 阶的张量，只有一个数字
* 向量（Vector）：1 阶的张量，也叫矢量，一个数组
* 矩阵（Matrix）：2 阶的张量，2 个轴通常称为行和列


* 维（dimension）通常用来描述向量，比如 N 维向量，比如“128 维特征值”。这里的维和
张量的轴定义不一样，这种 N 维向量描述的仍然是向量（即 1 阶张量），其中的 N 描述的
是数组的元素个数。

但是由于 2 阶张量（即矩阵）形似 2 维平面，3 阶张量形似 3 维空间，而 N 阶张量又可以

用 N 维数组来表示，导致维有时会被拿来形容张量的阶。为了避免混淆，尽量不要用维来
描述张量的阶。

我们以 numpy.ndarrry 类型的变量 t 的形状（t.shape）来说明：
* (1,)：标量，0 阶张量，1 维向量，只有 1 个数值
* (3,)：矢量，1 阶张量，3 维向量，有 3 个数值
* (5,)：矢量，1 阶张量，5 维向量，有 5 个数值
* (2,3)：矩阵，2 阶张量，有 6 个数值，t[0]为 3 维向量
* (3,1)：矩阵，2 阶张量，有 3 个值，t[0]为 1 维向量
* (3,4,5)：3 阶张量，有 60 个数值，t[0,0]为 5 维向量，t[0]为矩阵

### 特征向量/特征值
对于一个 n 行 n 列的矩阵 A，假设有标量λ和非零的 n 维向量 v 使 Av=λv
那么 v 是矩阵 A 的一个特征向量，标量λ是 v 对应的特征值。
